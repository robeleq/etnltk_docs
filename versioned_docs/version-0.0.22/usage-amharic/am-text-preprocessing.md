---
sidebar_position: 2
---

# Preprocessing

Performing text cleaning using `clean_amharic` function and `preprocessing` module:

- it provides a solid pipeline to clean and represent text data.

## 1. Text Cleaning using `clean_amharic` function
  
```python
from etnltk.lang.am import clean_amharic

sample_text = """
  рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊ.рѕЮ ­ЪцЌ рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх /Artificial Intelligence/ ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕхрЇБ рѕЃрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрІЊрѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇрЇБ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇрЇАрЇА

  рЅарѕЏрѕйріЋ рІЊрѕхрЅ░рѕЮрѕ« (Machine Learning) ріарѕЏріФріЮріљрЅх рІерїйрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕЦрѕГрІЊрЅх рѕѕрѕЏрѕ░рѕЇрїаріЋрЇБ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅхрЇц рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ /Natural Language Processing Tools/ рЅарѕўрїарЅђрѕЮ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇрЇб
"""

# `clean_amharic` function uses the default pipeline to clean text
cleaned = clean_amharic(input_text)

# print the `clean` text:
print(cleaned)
# output: рѕџрІФрІЮрІФ рІЊрѕўрЅ░ рѕЮрѕЁрѕерЅх рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕх рѕђрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕріарѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇ рЅарѕЏрѕйріЋ ріарѕхрЅ░рѕЮрѕ« ріарѕЏріФріЮріљрЅх рІерЇЁрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕхрѕГріарЅх рѕѕрѕЏрѕ░рѕЇрїаріЋ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅх рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ рЅарѕўрїарЅђрѕЮ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇ
```

The default pipeline for the `clean_amharic` method is the following:

1. `remove_links()` Replace all URLs.
2. `remove_tags()` Lowercase all HTML tags.
3. `remove_emojis()` Remove all emojis.
4. `remove_special_characters()` Remove all special characters (├Ц┬╝┬Ф┬Ц┬ф┬░┬Е├░┬▒┬Д┬х├д┬╣┬б┬│┬┐┬«├ц┬Б"РђЮРђю`Рђў┬┤РђЎРђџ,Рђъ┬╗┬ФсђїсђЇсђјсђЈ№╝ѕ№╝ЅсђћсђЋсђљсђЉсђісђІсђѕсђЅ).
5. `remove_digits()` Remove all blocks of digits.
6. `remove_ethiopic_digits()` Remove ethiopic number.
7. `remove_english_chars()` Remove all english characters.
8. `remove_arabic_chars()` Remove all arabic characters.
9. `remove_chinese_chars()` Remove all chinese characters.
10. `normalize_punct()` Normalizes ethiopic punctuations.
11. `normalize_shortened()` Expands all short form.
12. `remove_punct()` Remove all string.punctuation and ethiopic punctuations (рЇа рЇА рЇб рЇБ рЇц рЇЦ рЇд рЇД рЇе).
13. `remove_whitespaces()` Remove all white space between words.

## 2. Text Cleaning using a custom pipeline as argument to clean

- We can also pass a custom pipeline as argument to `clean_amharic` function

```python
from etnltk.lang.am import (
  preprocessing,
  clean_amharic
)

sample_text = """
  рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊ.рѕЮ ­ЪцЌ рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх /Artificial Intelligence/ ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕхрЇБ рѕЃрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрІЊрѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇрЇБ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇрЇАрЇА

  рЅарѕЏрѕйріЋ рІЊрѕхрЅ░рѕЮрѕ« (Machine Learning) ріарѕЏріФріЮріљрЅх рІерїйрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕЦрѕГрІЊрЅх рѕѕрѕЏрѕ░рѕЇрїаріЋрЇБ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅхрЇц рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ /Natural Language Processing Tools/ рЅарѕўрїарЅђрѕЮ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇрЇб
"""

# Define a custom preprocessor pipeline
custom_pipeline = [
  preprocessing.remove_emojis, 
  preprocessing.remove_digits,
  preprocessing.remove_ethiopic_punct,
  preprocessing.remove_english_chars, 
  preprocessing.remove_punct
]

# `clean_amharic` function takes a custom pipeline, if not uses the default pipeline
cleaned = clean_amharic(sample_text, abbrev=False, pipeline=custom_pipeline)
# print the `clean` text:
print(cleaned)
# output: рѕџрІФрІЮрІФ рІЊрѕўрЅ░ рѕЮрѕЁрѕерЅх рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕх рѕђрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕріарѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇ рЅарѕЏрѕйріЋ ріарѕхрЅ░рѕЮрѕ« ріарѕЏріФріЮріљрЅх рІерЇЁрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕхрѕГріарЅх рѕѕрѕЏрѕ░рѕЇрїаріЋ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅх рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ рЅарѕўрїарЅђрѕЮ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇ
```

## 3. Remove stopwords using `remove_stopwords` and `preprocessing` module

- `remove_stopwords` uses the default stopwords provided by the language.

```python
from etnltk.lang.am import preprocessing

amharic_words = ['рЅ░рѕеріЏ', 'рЅ░рѕеріЏ', 'ріарѕѕ', 'ріљрѕГрѕ▒', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'ріарЅцрЅх', 'рЅЦрѕѕрІЇ', 'рІерѕЂрѕѕрЅх', 'ріарѕўрЅх', 'рѕЇрїЃрЅИрІЇріЋ', 'рІГрІўрІЇ', 'рїѕрЅА', 'рѕЮріЉріЋ', 'ріљрІЇ', 'рІФрѕўрѕўрІЇ', 'рІХріГрЅ░рѕ»', 'рїарІерЅЂ', 'ріарІФрІЕрЅхрѕЮ', 'рЇђрїЅрѕЕ', 'рѕ│рѕхрЅирѕЇ', 'рѕєрІ▒', 'рЅ░ріљрЇЇрЅирѕЇ', 'рІхрІ▒рѕЮ', 'рІГрІ░рѕЏрѕЇ', 'ріарѕЅ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'рІХріГрЅ░рѕ»рѕЮ', 'рЅарїБрѕЮ', 'рІФрѕ│рІЮріЊрѕЇ', 'ріЦріЋрІ░рІџрѕЁ', 'рІФрІ░рѕерїѕрІЇ', 'рІерЅ░рѕўрїБрїаріљ', 'рѕЮрїЇрЅЦ', 'ріарѕѕрѕЏрїЇріўрЅ▒', 'ріљрІЇ', 'ріарѕЂріЋрѕЮ', 'рІѕрЅ░рЅх', 'ріЦріЋрЅЂрѕІрѕЇ', 'рѕЏрѕГ', 'ріарЅхріГрѕЇрЅхріЊ', 'рЇЇрѕФрЇЇрѕг', 'рІГрѕўрїЇрЅАрЅх', 'рЅХрѕј', 'рІГрѕ╗рѕѕрІІрѕЇ', 'рѕѕріарѕЂріЉ', 'рїЇріЋ', 'рѕўрІхрѕђріњрЅх', 'ріарІЮрѕѕрЅ│рѕѕрѕЂ', 'рЅарѕЏрѕѕрЅх', 'ріарѕхрѕерІирЅИрІЇ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│рѕЮ', 'рІѕрІГ', 'ріарѕѕрѕЏрІѕрЅЁ', 'рѕЇрїёріЋ', 'рЅарѕЮрїЇрЅЦ', 'ріЦрїЦрѕерЅх', 'рїѕрІхрІгрІЇ', 'ріљрЅарѕГ', 'рЅарѕЏрѕѕрЅх', 'ріарѕѕрЅђрѕ▒']

# Remove stop words
without_stopwords = preprocessing.remove_stopwords(amharic_words)

# print all list of words in a document with out the stop words:
print(without_stopwords)
# output: ['рЅ░рѕеріЏ', 'рЅ░рѕеріЏ', 'ріљрѕГрѕ▒', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'ріарЅцрЅх', 'рІерѕЂрѕѕрЅх', 'ріарѕўрЅх', 'рѕЇрїЃрЅИрІЇріЋ', 'рІГрІўрІЇ', 'рїѕрЅА', 'рѕЮріЉріЋ', 'рІФрѕўрѕўрІЇ', 'рІХріГрЅ░рѕ»', 'рїарІерЅЂ', 'ріарІФрІЕрЅхрѕЮ', 'рЇђрїЅрѕЕ', 'рѕ│рѕхрЅирѕЇ', 'рѕєрІ▒', 'рЅ░ріљрЇЇрЅирѕЇ', 'рІхрІ▒рѕЮ', 'рІГрІ░рѕЏрѕЇ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'рІХріГрЅ░рѕ»рѕЮ', 'рІФрѕ│рІЮріЊрѕЇ', 'рІФрІ░рѕерїѕрІЇ', 'рІерЅ░рѕўрїБрїаріљ', 'рѕЮрїЇрЅЦ', 'ріарѕѕрѕЏрїЇріўрЅ▒', 'ріарѕЂріЋрѕЮ', 'рІѕрЅ░рЅх', 'ріЦріЋрЅЂрѕІрѕЇ', 'рѕЏрѕГ', 'ріарЅхріГрѕЇрЅхріЊ', 'рЇЇрѕФрЇЇрѕг', 'рІГрѕўрїЇрЅАрЅх', 'рЅХрѕј', 'рІГрѕ╗рѕѕрІІрѕЇ', 'рѕѕріарѕЂріЉ', 'рѕўрІхрѕђріњрЅх', 'ріарІЮрѕѕрЅ│рѕѕрѕЂ', 'ріарѕхрѕерІирЅИрІЇ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│рѕЮ', 'рІѕрІГ', 'ріарѕѕрѕЏрІѕрЅЁ', 'рѕЇрїёріЋ', 'рЅарѕЮрїЇрЅЦ', 'ріЦрїЦрѕерЅх', 'рїѕрІхрІгрІЇ', 'ріарѕѕрЅђрѕ▒']
```

- `remove_stopwords` also can take custom stopwords

```python
from etnltk.lang.am import preprocessing
from etnltk.lang.am.stop_words import STOP_WORDS

amharic_words = ['рЅ░рѕеріЏ', 'рЅ░рѕеріЏ', 'ріарѕѕ', 'ріљрѕГрѕ▒', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'ріарЅцрЅх', 'рЅЦрѕѕрІЇ', 'рІерѕЂрѕѕрЅх', 'ріарѕўрЅх', 'рѕЇрїЃрЅИрІЇріЋ', 'рІГрІўрІЇ', 'рїѕрЅА', 'рѕЮріЉріЋ', 'ріљрІЇ', 'рІФрѕўрѕўрІЇ', 'рІХріГрЅ░рѕ»', 'рїарІерЅЂ', 'ріарІФрІЕрЅхрѕЮ', 'рЇђрїЅрѕЕ', 'рѕ│рѕхрЅирѕЇ', 'рѕєрІ▒', 'рЅ░ріљрЇЇрЅирѕЇ', 'рІхрІ▒рѕЮ', 'рІГрІ░рѕЏрѕЇ', 'ріарѕЅ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'рІХріГрЅ░рѕ»рѕЮ', 'рЅарїБрѕЮ', 'рІФрѕ│рІЮріЊрѕЇ', 'ріЦріЋрІ░рІџрѕЁ', 'рІФрІ░рѕерїѕрІЇ', 'рІерЅ░рѕўрїБрїаріљ', 'рѕЮрїЇрЅЦ', 'ріарѕѕрѕЏрїЇріўрЅ▒', 'ріљрІЇ', 'ріарѕЂріЋрѕЮ', 'рІѕрЅ░рЅх', 'ріЦріЋрЅЂрѕІрѕЇ', 'рѕЏрѕГ', 'ріарЅхріГрѕЇрЅхріЊ', 'рЇЇрѕФрЇЇрѕг', 'рІГрѕўрїЇрЅАрЅх', 'рЅХрѕј', 'рІГрѕ╗рѕѕрІІрѕЇ', 'рѕѕріарѕЂріЉ', 'рїЇріЋ', 'рѕўрІхрѕђріњрЅх', 'ріарІЮрѕѕрЅ│рѕѕрѕЂ', 'рЅарѕЏрѕѕрЅх', 'ріарѕхрѕерІирЅИрІЇ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│рѕЮ', 'рІѕрІГ', 'ріарѕѕрѕЏрІѕрЅЁ', 'рѕЇрїёріЋ', 'рЅарѕЮрїЇрЅЦ', 'ріЦрїЦрѕерЅх', 'рїѕрІхрІгрІЇ', 'ріљрЅарѕГ', 'рЅарѕЏрѕѕрЅх', 'ріарѕѕрЅђрѕ▒']

# Define a custom stopwords
default_stopwords = STOP_WORDS
custom_stopwords = default_stopwords.union(set(["рІѕрІГ", "ріарѕўрЅх", "рІѕрІГрІўрѕ«"]))

# Remove stop words
without_stopwords = preprocessing.remove_stopwords(amharic_words, stop_words=custom_stopwords)

# print all list of words in a document with out the stop words:
print(without_stopwords)
# output: ['рЅ░рѕеріЏ', 'рЅ░рѕеріЏ', 'ріљрѕГрѕ▒', 'рЅ│рѕфрі│', 'ріарЅцрЅх', 'рІерѕЂрѕѕрЅх', 'рѕЇрїЃрЅИрІЇріЋ', 'рІГрІўрІЇ', 'рїѕрЅА', 'рѕЮріЉріЋ', 'рІФрѕўрѕўрІЇ', 'рІХріГрЅ░рѕ»', 'рїарІерЅЂ', 'ріарІФрІЕрЅхрѕЮ', 'рЇђрїЅрѕЕ', 'рѕ│рѕхрЅирѕЇ', 'рѕєрІ▒', 'рЅ░ріљрЇЇрЅирѕЇ', 'рІхрІ▒рѕЮ', 'рІГрІ░рѕЏрѕЇ', 'рЅ│рѕфрі│', 'рІХріГрЅ░рѕ»рѕЮ', 'рІФрѕ│рІЮріЊрѕЇ', 'рІФрІ░рѕерїѕрІЇ', 'рІерЅ░рѕўрїБрїаріљ', 'рѕЮрїЇрЅЦ', 'ріарѕѕрѕЏрїЇріўрЅ▒', 'ріарѕЂріЋрѕЮ', 'рІѕрЅ░рЅх', 'ріЦріЋрЅЂрѕІрѕЇ', 'рѕЏрѕГ', 'ріарЅхріГрѕЇрЅхріЊ', 'рЇЇрѕФрЇЇрѕг', 'рІГрѕўрїЇрЅАрЅх', 'рЅХрѕј', 'рІГрѕ╗рѕѕрІІрѕЇ', 'рѕѕріарѕЂріЉ', 'рѕўрІхрѕђріњрЅх', 'ріарІЮрѕѕрЅ│рѕѕрѕЂ', 'ріарѕхрѕерІирЅИрІЇ', 'рЅ│рѕфрі│рѕЮ', 'ріарѕѕрѕЏрІѕрЅЁ', 'рѕЇрїёріЋ', 'рЅарѕЮрїЇрЅЦ', 'ріЦрїЦрѕерЅх', 'рїѕрІхрІгрІЇ', 'ріарѕѕрЅђрѕ▒']
```

### Preprocessing API

The complete preprocessing API can be found at the following address: [preprocessing functions](./functions/#1-text-preprocessing-functions)
